{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjE0M1VsiF7a"
      },
      "source": [
        "# Comparing Test Results Amongst Complex Investors\n",
        "\n",
        "This test will use the same synthetic data in the placebo testing. We will test on two separate sets, one that contains only standard investors and the other on only complex."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNrhVNxUiAcx",
        "outputId": "02edddc6-a85c-4872-a402-a1a086b15518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sqlalchemy\n",
            "  Downloading sqlalchemy-2.0.43-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting greenlet>=1 (from sqlalchemy)\n",
            "  Downloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (4.15.0)\n",
            "Downloading sqlalchemy-2.0.43-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (607 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m607.6/607.6 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: greenlet, sqlalchemy\n",
            "Successfully installed greenlet-3.2.4 sqlalchemy-2.0.43\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting graphviz (from catboost)\n",
            "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: graphviz, catboost\n",
            "Successfully installed catboost-1.2.8 graphviz-0.21\n"
          ]
        }
      ],
      "source": [
        "!pip install sqlalchemy\n",
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETPXIgXdjtD0",
        "outputId": "aa18f416-3a88-4f97-cda3-1fd34c5f67f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Training model: syn_catboost_model.cbm\n",
            "0:\ttest: 0.9569145\tbest: 0.9569145 (0)\ttotal: 5.38s\tremaining: 1h 29m 32s\n",
            "1:\ttest: 0.9613223\tbest: 0.9613223 (1)\ttotal: 10.2s\tremaining: 1h 25m 9s\n",
            "2:\ttest: 0.9611631\tbest: 0.9613223 (1)\ttotal: 15.1s\tremaining: 1h 23m 48s\n",
            "3:\ttest: 0.9609051\tbest: 0.9613223 (1)\ttotal: 20.4s\tremaining: 1h 24m 40s\n",
            "4:\ttest: 0.9627077\tbest: 0.9627077 (4)\ttotal: 25.9s\tremaining: 1h 25m 48s\n",
            "5:\ttest: 0.9637609\tbest: 0.9637609 (5)\ttotal: 31.2s\tremaining: 1h 26m 6s\n",
            "6:\ttest: 0.9637221\tbest: 0.9637609 (5)\ttotal: 36.3s\tremaining: 1h 25m 46s\n",
            "7:\ttest: 0.9635029\tbest: 0.9637609 (5)\ttotal: 41.6s\tremaining: 1h 25m 55s\n",
            "8:\ttest: 0.9635418\tbest: 0.9637609 (5)\ttotal: 46.3s\tremaining: 1h 24m 54s\n",
            "9:\ttest: 0.9632837\tbest: 0.9637609 (5)\ttotal: 51.3s\tremaining: 1h 24m 40s\n",
            "10:\ttest: 0.9635029\tbest: 0.9637609 (5)\ttotal: 56.6s\tremaining: 1h 24m 46s\n",
            "11:\ttest: 0.9634640\tbest: 0.9637609 (5)\ttotal: 1m 1s\tremaining: 1h 24m 46s\n",
            "12:\ttest: 0.9635418\tbest: 0.9637609 (5)\ttotal: 1m 6s\tremaining: 1h 24m 19s\n",
            "13:\ttest: 0.9635029\tbest: 0.9637609 (5)\ttotal: 1m 11s\tremaining: 1h 24m 25s\n",
            "14:\ttest: 0.9638317\tbest: 0.9638317 (14)\ttotal: 1m 16s\tremaining: 1h 24m 6s\n",
            "15:\ttest: 0.9638705\tbest: 0.9638705 (15)\ttotal: 1m 22s\tremaining: 1h 24m 4s\n",
            "16:\ttest: 0.9645280\tbest: 0.9645280 (16)\ttotal: 1m 27s\tremaining: 1h 23m 50s\n",
            "17:\ttest: 0.9648956\tbest: 0.9648956 (17)\ttotal: 1m 31s\tremaining: 1h 23m 23s\n",
            "18:\ttest: 0.9650830\tbest: 0.9650830 (18)\ttotal: 1m 36s\tremaining: 1h 23m 9s\n",
            "19:\ttest: 0.9654506\tbest: 0.9654506 (19)\ttotal: 1m 41s\tremaining: 1h 22m 58s\n",
            "20:\ttest: 0.9657016\tbest: 0.9657016 (20)\ttotal: 1m 46s\tremaining: 1h 22m 33s\n",
            "21:\ttest: 0.9658112\tbest: 0.9658112 (21)\ttotal: 1m 51s\tremaining: 1h 22m 39s\n",
            "22:\ttest: 0.9656627\tbest: 0.9658112 (21)\ttotal: 1m 56s\tremaining: 1h 22m 34s\n",
            "23:\ttest: 0.9654754\tbest: 0.9658112 (21)\ttotal: 2m 1s\tremaining: 1h 22m 33s\n",
            "24:\ttest: 0.9659526\tbest: 0.9659526 (24)\ttotal: 2m 6s\tremaining: 1h 22m 30s\n",
            "25:\ttest: 0.9660622\tbest: 0.9660622 (25)\ttotal: 2m 11s\tremaining: 1h 22m 16s\n",
            "26:\ttest: 0.9659526\tbest: 0.9660622 (25)\ttotal: 2m 17s\tremaining: 1h 22m 18s\n",
            "27:\ttest: 0.9662106\tbest: 0.9662106 (27)\ttotal: 2m 22s\tremaining: 1h 22m 13s\n",
            "28:\ttest: 0.9662106\tbest: 0.9662106 (27)\ttotal: 2m 27s\tremaining: 1h 22m 5s\n",
            "29:\ttest: 0.9662106\tbest: 0.9662106 (27)\ttotal: 2m 32s\tremaining: 1h 21m 56s\n",
            "30:\ttest: 0.9661717\tbest: 0.9662106 (27)\ttotal: 2m 36s\tremaining: 1h 21m 45s\n",
            "31:\ttest: 0.9667196\tbest: 0.9667196 (31)\ttotal: 2m 41s\tremaining: 1h 21m 33s\n",
            "32:\ttest: 0.9667903\tbest: 0.9667903 (32)\ttotal: 2m 46s\tremaining: 1h 21m 19s\n",
            "33:\ttest: 0.9669388\tbest: 0.9669388 (33)\ttotal: 2m 51s\tremaining: 1h 21m 11s\n",
            "34:\ttest: 0.9668611\tbest: 0.9669388 (33)\ttotal: 2m 56s\tremaining: 1h 21m 5s\n",
            "35:\ttest: 0.9669318\tbest: 0.9669388 (33)\ttotal: 3m 1s\tremaining: 1h 20m 55s\n",
            "36:\ttest: 0.9672287\tbest: 0.9672287 (36)\ttotal: 3m 6s\tremaining: 1h 20m 49s\n",
            "37:\ttest: 0.9672287\tbest: 0.9672287 (36)\ttotal: 3m 11s\tremaining: 1h 20m 44s\n",
            "38:\ttest: 0.9677836\tbest: 0.9677836 (38)\ttotal: 3m 16s\tremaining: 1h 20m 39s\n",
            "39:\ttest: 0.9676352\tbest: 0.9677836 (38)\ttotal: 3m 21s\tremaining: 1h 20m 36s\n",
            "40:\ttest: 0.9676352\tbest: 0.9677836 (38)\ttotal: 3m 26s\tremaining: 1h 20m 24s\n",
            "41:\ttest: 0.9677448\tbest: 0.9677836 (38)\ttotal: 3m 31s\tremaining: 1h 20m 16s\n",
            "42:\ttest: 0.9677448\tbest: 0.9677836 (38)\ttotal: 3m 36s\tremaining: 1h 20m 17s\n",
            "43:\ttest: 0.9680735\tbest: 0.9680735 (43)\ttotal: 3m 41s\tremaining: 1h 20m 17s\n",
            "44:\ttest: 0.9679639\tbest: 0.9680735 (43)\ttotal: 3m 46s\tremaining: 1h 20m 12s\n",
            "45:\ttest: 0.9681124\tbest: 0.9681124 (45)\ttotal: 3m 51s\tremaining: 1h 20m 11s\n",
            "46:\ttest: 0.9685189\tbest: 0.9685189 (46)\ttotal: 3m 56s\tremaining: 1h 20m 3s\n",
            "47:\ttest: 0.9685577\tbest: 0.9685577 (47)\ttotal: 4m 2s\tremaining: 1h 20m 5s\n",
            "48:\ttest: 0.9685189\tbest: 0.9685577 (47)\ttotal: 4m 7s\tremaining: 1h 20m\n",
            "49:\ttest: 0.9685577\tbest: 0.9685577 (47)\ttotal: 4m 11s\tremaining: 1h 19m 47s\n",
            "50:\ttest: 0.9685577\tbest: 0.9685577 (47)\ttotal: 4m 17s\tremaining: 1h 19m 47s\n",
            "51:\ttest: 0.9685577\tbest: 0.9685577 (47)\ttotal: 4m 22s\tremaining: 1h 19m 48s\n",
            "52:\ttest: 0.9686355\tbest: 0.9686355 (52)\ttotal: 4m 27s\tremaining: 1h 19m 46s\n",
            "53:\ttest: 0.9685966\tbest: 0.9686355 (52)\ttotal: 4m 32s\tremaining: 1h 19m 41s\n",
            "54:\ttest: 0.9687062\tbest: 0.9687062 (54)\ttotal: 4m 38s\tremaining: 1h 19m 37s\n",
            "55:\ttest: 0.9687062\tbest: 0.9687062 (54)\ttotal: 4m 43s\tremaining: 1h 19m 38s\n",
            "56:\ttest: 0.9687451\tbest: 0.9687451 (56)\ttotal: 4m 48s\tremaining: 1h 19m 25s\n",
            "57:\ttest: 0.9688546\tbest: 0.9688546 (57)\ttotal: 4m 53s\tremaining: 1h 19m 20s\n",
            "58:\ttest: 0.9690031\tbest: 0.9690031 (58)\ttotal: 4m 58s\tremaining: 1h 19m 21s\n",
            "59:\ttest: 0.9690031\tbest: 0.9690031 (58)\ttotal: 5m 3s\tremaining: 1h 19m 21s\n",
            "60:\ttest: 0.9690031\tbest: 0.9690031 (58)\ttotal: 5m 9s\tremaining: 1h 19m 21s\n",
            "61:\ttest: 0.9689324\tbest: 0.9690031 (58)\ttotal: 5m 14s\tremaining: 1h 19m 21s\n",
            "62:\ttest: 0.9691197\tbest: 0.9691197 (62)\ttotal: 5m 20s\tremaining: 1h 19m 20s\n",
            "63:\ttest: 0.9691197\tbest: 0.9691197 (62)\ttotal: 5m 25s\tremaining: 1h 19m 19s\n",
            "64:\ttest: 0.9691197\tbest: 0.9691197 (62)\ttotal: 5m 30s\tremaining: 1h 19m 9s\n",
            "65:\ttest: 0.9692293\tbest: 0.9692293 (65)\ttotal: 5m 34s\tremaining: 1h 19m\n",
            "66:\ttest: 0.9694873\tbest: 0.9694873 (66)\ttotal: 5m 39s\tremaining: 1h 18m 52s\n",
            "67:\ttest: 0.9695262\tbest: 0.9695262 (67)\ttotal: 5m 45s\tremaining: 1h 18m 48s\n",
            "68:\ttest: 0.9695262\tbest: 0.9695262 (67)\ttotal: 5m 50s\tremaining: 1h 18m 47s\n",
            "69:\ttest: 0.9695262\tbest: 0.9695262 (67)\ttotal: 5m 55s\tremaining: 1h 18m 43s\n",
            "70:\ttest: 0.9695262\tbest: 0.9695262 (67)\ttotal: 6m\tremaining: 1h 18m 40s\n",
            "71:\ttest: 0.9696358\tbest: 0.9696358 (71)\ttotal: 6m 5s\tremaining: 1h 18m 35s\n",
            "72:\ttest: 0.9697843\tbest: 0.9697843 (72)\ttotal: 6m 10s\tremaining: 1h 18m 26s\n",
            "73:\ttest: 0.9697454\tbest: 0.9697843 (72)\ttotal: 6m 15s\tremaining: 1h 18m 18s\n",
            "74:\ttest: 0.9697454\tbest: 0.9697843 (72)\ttotal: 6m 20s\tremaining: 1h 18m 14s\n",
            "75:\ttest: 0.9698550\tbest: 0.9698550 (75)\ttotal: 6m 25s\tremaining: 1h 18m 7s\n",
            "76:\ttest: 0.9700423\tbest: 0.9700423 (76)\ttotal: 6m 30s\tremaining: 1h 18m\n",
            "77:\ttest: 0.9700423\tbest: 0.9700423 (76)\ttotal: 6m 35s\tremaining: 1h 18m\n",
            "78:\ttest: 0.9700812\tbest: 0.9700812 (78)\ttotal: 6m 41s\tremaining: 1h 17m 56s\n",
            "79:\ttest: 0.9700812\tbest: 0.9700812 (78)\ttotal: 6m 46s\tremaining: 1h 17m 51s\n",
            "80:\ttest: 0.9700812\tbest: 0.9700812 (78)\ttotal: 6m 51s\tremaining: 1h 17m 45s\n",
            "81:\ttest: 0.9700812\tbest: 0.9700812 (78)\ttotal: 6m 56s\tremaining: 1h 17m 42s\n",
            "82:\ttest: 0.9700812\tbest: 0.9700812 (78)\ttotal: 7m 1s\tremaining: 1h 17m 41s\n",
            "83:\ttest: 0.9700812\tbest: 0.9700812 (78)\ttotal: 7m 7s\tremaining: 1h 17m 38s\n",
            "84:\ttest: 0.9701200\tbest: 0.9701200 (84)\ttotal: 7m 12s\tremaining: 1h 17m 31s\n",
            "85:\ttest: 0.9702296\tbest: 0.9702296 (85)\ttotal: 7m 16s\tremaining: 1h 17m 23s\n",
            "86:\ttest: 0.9702296\tbest: 0.9702296 (85)\ttotal: 7m 22s\tremaining: 1h 17m 21s\n",
            "87:\ttest: 0.9702685\tbest: 0.9702685 (87)\ttotal: 7m 27s\tremaining: 1h 17m 19s\n",
            "88:\ttest: 0.9701200\tbest: 0.9702685 (87)\ttotal: 7m 32s\tremaining: 1h 17m 12s\n",
            "89:\ttest: 0.9702296\tbest: 0.9702685 (87)\ttotal: 7m 37s\tremaining: 1h 17m 9s\n",
            "90:\ttest: 0.9701908\tbest: 0.9702685 (87)\ttotal: 7m 43s\tremaining: 1h 17m 6s\n",
            "91:\ttest: 0.9702296\tbest: 0.9702685 (87)\ttotal: 7m 48s\tremaining: 1h 17m 3s\n",
            "92:\ttest: 0.9702296\tbest: 0.9702685 (87)\ttotal: 7m 53s\tremaining: 1h 16m 56s\n",
            "93:\ttest: 0.9702685\tbest: 0.9702685 (87)\ttotal: 7m 58s\tremaining: 1h 16m 54s\n",
            "94:\ttest: 0.9702685\tbest: 0.9702685 (87)\ttotal: 8m 4s\tremaining: 1h 16m 51s\n",
            "95:\ttest: 0.9702685\tbest: 0.9702685 (87)\ttotal: 8m 8s\tremaining: 1h 16m 44s\n",
            "96:\ttest: 0.9704877\tbest: 0.9704877 (96)\ttotal: 8m 14s\tremaining: 1h 16m 39s\n",
            "97:\ttest: 0.9705972\tbest: 0.9705972 (97)\ttotal: 8m 19s\tremaining: 1h 16m 37s\n",
            "98:\ttest: 0.9705972\tbest: 0.9705972 (97)\ttotal: 8m 24s\tremaining: 1h 16m 34s\n",
            "99:\ttest: 0.9704877\tbest: 0.9705972 (97)\ttotal: 8m 30s\tremaining: 1h 16m 30s\n",
            "100:\ttest: 0.9704877\tbest: 0.9705972 (97)\ttotal: 8m 35s\tremaining: 1h 16m 24s\n",
            "101:\ttest: 0.9704877\tbest: 0.9705972 (97)\ttotal: 8m 40s\tremaining: 1h 16m 22s\n",
            "102:\ttest: 0.9704877\tbest: 0.9705972 (97)\ttotal: 8m 45s\tremaining: 1h 16m 19s\n",
            "103:\ttest: 0.9704877\tbest: 0.9705972 (97)\ttotal: 8m 50s\tremaining: 1h 16m 13s\n",
            "104:\ttest: 0.9704877\tbest: 0.9705972 (97)\ttotal: 8m 55s\tremaining: 1h 16m 7s\n",
            "105:\ttest: 0.9704877\tbest: 0.9705972 (97)\ttotal: 9m 1s\tremaining: 1h 16m 4s\n",
            "106:\ttest: 0.9704877\tbest: 0.9705972 (97)\ttotal: 9m 6s\tremaining: 1h 15m 56s\n",
            "107:\ttest: 0.9704877\tbest: 0.9705972 (97)\ttotal: 9m 10s\tremaining: 1h 15m 48s\n",
            "Stopped by overfitting detector  (10 iterations wait)\n",
            "\n",
            "bestTest = 0.9705972474\n",
            "bestIteration = 97\n",
            "\n",
            "Shrink model to first 98 iterations.\n",
            "\n",
            "Model saved to: syn_catboost_model.cbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1684516121.py:46: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  topk = df.groupby(\"clean_row_id\", group_keys=False).apply(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics (Validation Set):\n",
            "Accuracy@1 : 0.9287\n",
            "Recall@3   : 0.9964\n",
            "MRR        : 0.9623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1684516121.py:59: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  mrr = df.groupby(\"clean_row_id\", group_keys=False).apply(reciprocal_rank).mean()\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from catboost import CatBoostRanker, Pool\n",
        "from typing import Tuple\n",
        "\n",
        "# Paths to files in Drive\n",
        "_DB_PATH = \"/content/drive/MyDrive/Colab Notebooks/database.db\"\n",
        "STD_TEST_IDS = \"test_ids_standard_only.csv\"\n",
        "COMP_TEST_IDS = \"test_ids_complex_only.csv\"\n",
        "VAL_IDS = \"val_ids_cult_bias.csv\"\n",
        "\n",
        "# Tuned hyperparameters\n",
        "_BEST_PARAMS = {\n",
        "    \"loss_function\": \"YetiRank\",\n",
        "    \"eval_metric\": \"NDCG:top=3\",\n",
        "    \"random_seed\": 42,\n",
        "    \"learning_rate\": 0.13275757957731918,\n",
        "    \"depth\": 6,\n",
        "    \"l2_leaf_reg\": 7.142519331365267,\n",
        "    \"random_strength\": 3.395785387976391,\n",
        "    \"min_data_in_leaf\": 84,\n",
        "    \"subsample\": 0.9048958560910838,\n",
        "    \"colsample_bylevel\": 0.511123337191838,\n",
        "    \"grow_policy\": \"Lossguide\",\n",
        "}\n",
        "\n",
        "\n",
        "def _compute_ranking_metrics(df: pd.DataFrame, k: int = 3):\n",
        "    \"\"\"\n",
        "    Compute Accuracy@1, Recall@k, and MRR for a ranking prediction dataframe.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Must contain columns ['clean_row_id', 'score', 'label']\n",
        "        k (int): The cutoff rank for recall@k\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float, float]: (Accuracy@1, Recall@k, MRR)\n",
        "    \"\"\"\n",
        "    # Accuracy@1\n",
        "    top1 = df.loc[df.groupby(\"clean_row_id\")[\"score\"].idxmax()]\n",
        "    acc1 = (top1[\"label\"] == 1).mean()\n",
        "\n",
        "    # Recall@k\n",
        "    topk = df.groupby(\"clean_row_id\", group_keys=False).apply(\n",
        "        lambda g: g.nlargest(k, \"score\")\n",
        "    )\n",
        "    recall_k = topk.groupby(\"clean_row_id\")[\"label\"].max().mean()\n",
        "\n",
        "    # MRR\n",
        "    def reciprocal_rank(g: pd.DataFrame) -> float:\n",
        "        labels_sorted = g.sort_values(\"score\", ascending=False)[\"label\"].to_numpy()\n",
        "        for rank, label in enumerate(labels_sorted, start=1):\n",
        "            if label == 1:\n",
        "                return 1.0 / rank\n",
        "        return 0.0\n",
        "\n",
        "    mrr = df.groupby(\"clean_row_id\", group_keys=False).apply(reciprocal_rank).mean()\n",
        "\n",
        "    return acc1, recall_k, mrr\n",
        "\n",
        "\n",
        "def _train_catboost_model(\n",
        "    parameters: dict,\n",
        "    train_df: pd.DataFrame,\n",
        "    val_df: pd.DataFrame,\n",
        "    n_rounds: int = 500,\n",
        "    model_output_path: str = \"catboost_model.cbm\",\n",
        ") -> CatBoostRanker:\n",
        "    \"\"\"\n",
        "    Trains a CatBoost ranking model using the provided training and validation data.\n",
        "\n",
        "    Args:\n",
        "        parameters (dict): Parameters for CatBoostRanker.\n",
        "        train_df (pd.DataFrame): Training data with label, group info, and features.\n",
        "        val_df (pd.DataFrame): Validation data with same structure.\n",
        "        n_rounds (int): Maximum number of boosting rounds.\n",
        "        model_output_path (str): File path to save the trained CatBoost model.\n",
        "\n",
        "    Returns:\n",
        "        CatBoostRanker: Trained CatBoost model.\n",
        "    \"\"\"\n",
        "    drop_cols = [\"label\", \"clean_row_id\", \"investor\", \"firm\", \"template_id\"]\n",
        "\n",
        "    # Train\n",
        "    train_group_sizes = train_df.groupby(\"clean_row_id\", sort=False).size().tolist()\n",
        "    train_group_id = np.repeat(np.arange(len(train_group_sizes)), train_group_sizes)\n",
        "\n",
        "    X_train = train_df.drop(columns=drop_cols)\n",
        "    y_train = train_df[\"label\"]\n",
        "    del train_df  # Free memory early\n",
        "\n",
        "    train_pool = Pool(data=X_train, label=y_train, group_id=train_group_id)\n",
        "    del X_train, y_train, train_group_id  # Free memory\n",
        "    gc.collect()  # Call garbage collector to be extra sure\n",
        "\n",
        "    # Validation\n",
        "    val_group_sizes = val_df.groupby(\"clean_row_id\", sort=False).size().tolist()\n",
        "    val_group_id = np.repeat(np.arange(len(val_group_sizes)), val_group_sizes)\n",
        "\n",
        "    X_val = val_df.drop(columns=drop_cols)\n",
        "    y_val = val_df[\"label\"]\n",
        "\n",
        "    val_pool = Pool(data=X_val, label=y_val, group_id=val_group_id)\n",
        "    del X_val, y_val, val_group_id  # Free memory\n",
        "    gc.collect()  # Call garbage collector to be extra sure\n",
        "\n",
        "    # Train model\n",
        "    model = CatBoostRanker(iterations=n_rounds, **parameters)\n",
        "    model.fit(\n",
        "        train_pool,\n",
        "        eval_set=val_pool,\n",
        "        early_stopping_rounds=10,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "    # Save model\n",
        "    model.save_model(model_output_path)\n",
        "    print(f\"\\nModel saved to: {model_output_path}\")\n",
        "\n",
        "    # Score model\n",
        "    val_df = val_df.copy()  # preserve original structure\n",
        "    val_df[\"score\"] = model.predict(val_pool)\n",
        "\n",
        "    acc1, recall3, mrr = _compute_ranking_metrics(val_df, k=3)\n",
        "\n",
        "    print(\"\\nEvaluation Metrics (Validation Set):\")\n",
        "    print(f\"Accuracy@1 : {acc1:.4f}\")\n",
        "    print(f\"Recall@3   : {recall3:.4f}\")\n",
        "    print(f\"MRR        : {mrr:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_syn_and_ran_model(\n",
        "    n_rounds: int = 1000,\n",
        "):\n",
        "    \"\"\"\n",
        "    Trains two CatBoost ranking models on pre-split data and saves them to disk.\n",
        "\n",
        "    The models are saved in `.cbm` format for compatibility with CatBoost's C++ inference engine.\n",
        "\n",
        "    Args:\n",
        "        n_rounds (int): Maximum number of boosting rounds for training (default: 1000).\n",
        "    \"\"\"\n",
        "    # Mount drive\n",
        "    import sys\n",
        "\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        from google.colab import drive\n",
        "\n",
        "        drive.mount(\"/content/drive\")\n",
        "\n",
        "    def train_model(\n",
        "        data_table: str, val_ids_path: str, model_path: str\n",
        "    ):\n",
        "        print(f\"Training model: {model_path}\")\n",
        "        # Get ids\n",
        "        val_ids = (\n",
        "            pd.read_csv(val_ids_path)[\"val_ids\"].dropna().astype(int).tolist()\n",
        "        )\n",
        "        std_test_ids = (\n",
        "            pd.read_csv(STD_TEST_IDS)[\"test_ids_standard\"].dropna().astype(int).tolist()\n",
        "        )\n",
        "\n",
        "        comp_test_ids = (\n",
        "            pd.read_csv(COMP_TEST_IDS)[\"test_ids_complex\"].dropna().astype(int).tolist()\n",
        "        )\n",
        "\n",
        "        test_ids = std_test_ids + comp_test_ids\n",
        "\n",
        "        # Get data\n",
        "        chunk_size = 100000\n",
        "        chunks = []\n",
        "        with sqlite3.connect(_DB_PATH) as conn:\n",
        "            for chunk in pd.read_sql_query(f\"SELECT * FROM {data_table}\", conn, chunksize=chunk_size):\n",
        "                chunks.append(chunk)\n",
        "            full_df = pd.concat(chunks, ignore_index=True)\n",
        "\n",
        "        # Split the set\n",
        "        val_ids_set = set(val_ids)\n",
        "        test_ids_set = set(test_ids)\n",
        "        excluded_ids = val_ids_set | test_ids_set\n",
        "        val_df = full_df[full_df[\"clean_row_id\"].isin(val_ids_set)]\n",
        "        full_df = full_df[~full_df[\"clean_row_id\"].isin(excluded_ids)]\n",
        "\n",
        "        # Train model\n",
        "        return _train_catboost_model(\n",
        "            _BEST_PARAMS, full_df, val_df, n_rounds, model_path\n",
        "        )\n",
        "\n",
        "    # Start with standard\n",
        "    syn = train_model(\"feature_matrix\", VAL_IDS, \"syn_catboost_model.cbm\")\n",
        "\n",
        "    return syn\n",
        "\n",
        "syn = train_syn_and_ran_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3CyvKVnqNTv"
      },
      "source": [
        "Ok Models are trained. Synthetic case performed significantly better in validation with ~93% Accuracy@1 whereas the placebo set achieved ~45% Accuracy@1.\n",
        "\n",
        "Let's run the test set to be sure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmwQArAwqNTw",
        "outputId": "b1ca3d53-b739-438e-ef22-1ef2d539ee38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1684516121.py:46: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  topk = df.groupby(\"clean_row_id\", group_keys=False).apply(\n",
            "/tmp/ipython-input-1684516121.py:59: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  mrr = df.groupby(\"clean_row_id\", group_keys=False).apply(reciprocal_rank).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics (Standard Investors Test Set):\n",
            "Accuracy@1 : 0.9340\n",
            "Recall@3   : 0.9975\n",
            "MRR        : 0.9650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1684516121.py:46: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  topk = df.groupby(\"clean_row_id\", group_keys=False).apply(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics (Complex Investors Test Set):\n",
            "Accuracy@1 : 0.9120\n",
            "Recall@3   : 0.9960\n",
            "MRR        : 0.9526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1684516121.py:59: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  mrr = df.groupby(\"clean_row_id\", group_keys=False).apply(reciprocal_rank).mean()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.912), np.float64(0.996), np.float64(0.9526011904761905))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "def evaluate_on_test(model, test_ids_path, id_col_name: str, data_table: str, label=\"\"):\n",
        "    # Load test IDs\n",
        "    test_ids = pd.read_csv(test_ids_path)[id_col_name].dropna().astype(int).tolist()\n",
        "    test_ids_set = set(test_ids)\n",
        "\n",
        "    # Load test rows from DB\n",
        "    with sqlite3.connect(_DB_PATH) as conn:\n",
        "        test_df = pd.read_sql_query(\n",
        "            f\"SELECT * FROM {data_table} WHERE clean_row_id IN ({','.join(map(str, test_ids_set))})\",\n",
        "            conn,\n",
        "        )\n",
        "\n",
        "    # Drop non-feature columns\n",
        "    drop_cols = [\"label\", \"clean_row_id\", \"investor\", \"firm\", \"template_id\"]\n",
        "    group_sizes = test_df.groupby(\"clean_row_id\", sort=False).size().tolist()\n",
        "    group_id = np.repeat(np.arange(len(group_sizes)), group_sizes)\n",
        "\n",
        "    X_test = test_df.drop(columns=drop_cols)\n",
        "    y_test = test_df[\"label\"]\n",
        "\n",
        "    test_pool = Pool(data=X_test, label=y_test, group_id=group_id)\n",
        "    test_df[\"score\"] = model.predict(test_pool)\n",
        "\n",
        "    acc1, recall3, mrr = _compute_ranking_metrics(test_df, k=3)\n",
        "    print(f\"\\nEvaluation Metrics ({label} Test Set):\")\n",
        "    print(f\"Accuracy@1 : {acc1:.4f}\")\n",
        "    print(f\"Recall@3   : {recall3:.4f}\")\n",
        "    print(f\"MRR        : {mrr:.4f}\")\n",
        "\n",
        "    return acc1, recall3, mrr\n",
        "\n",
        "# Evaluate both models on their test sets\n",
        "evaluate_on_test(syn, STD_TEST_IDS, \"test_ids_standard\", \"feature_matrix\", label=\"Standard Investors\")\n",
        "evaluate_on_test(syn, COMP_TEST_IDS, \"test_ids_complex\", \"feature_matrix\", label=\"Complex Investors\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}