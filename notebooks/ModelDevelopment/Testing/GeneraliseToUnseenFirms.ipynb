{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjE0M1VsiF7a"
      },
      "source": [
        "# Test on Unseen Investors\n",
        "\n",
        "This test will use the same synthetic data in the placebo testing. We will test on unseen investors to see how it generalizes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNrhVNxUiAcx",
        "outputId": "8e7c9706-4f04-4635-974e-7b3a2c8f7ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.12/dist-packages (2.0.43)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (3.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (4.15.0)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install sqlalchemy\n",
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETPXIgXdjtD0",
        "outputId": "1d5d84bd-dac4-4a1a-8285-7318e522e4dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Training model: syn_catboost_model.cbm\n",
            "0:\ttest: 0.9513036\tbest: 0.9513036 (0)\ttotal: 5.45s\tremaining: 1h 30m 49s\n",
            "1:\ttest: 0.9546053\tbest: 0.9546053 (1)\ttotal: 10.3s\tremaining: 1h 25m 18s\n",
            "2:\ttest: 0.9561490\tbest: 0.9561490 (2)\ttotal: 15.6s\tremaining: 1h 26m 31s\n",
            "3:\ttest: 0.9598476\tbest: 0.9598476 (3)\ttotal: 21.1s\tremaining: 1h 27m 27s\n",
            "4:\ttest: 0.9602166\tbest: 0.9602166 (4)\ttotal: 26.3s\tremaining: 1h 27m 22s\n",
            "5:\ttest: 0.9600500\tbest: 0.9602166 (4)\ttotal: 31.4s\tremaining: 1h 26m 42s\n",
            "6:\ttest: 0.9612245\tbest: 0.9612245 (6)\ttotal: 36.6s\tremaining: 1h 26m 28s\n",
            "7:\ttest: 0.9614785\tbest: 0.9614785 (7)\ttotal: 41.7s\tremaining: 1h 26m 5s\n",
            "8:\ttest: 0.9619348\tbest: 0.9619348 (8)\ttotal: 46.9s\tremaining: 1h 26m 3s\n",
            "9:\ttest: 0.9622682\tbest: 0.9622682 (9)\ttotal: 52.3s\tremaining: 1h 26m 14s\n",
            "10:\ttest: 0.9625221\tbest: 0.9625221 (10)\ttotal: 57.3s\tremaining: 1h 25m 54s\n",
            "11:\ttest: 0.9635063\tbest: 0.9635063 (11)\ttotal: 1m 2s\tremaining: 1h 25m 25s\n",
            "12:\ttest: 0.9639111\tbest: 0.9639111 (12)\ttotal: 1m 7s\tremaining: 1h 25m 28s\n",
            "13:\ttest: 0.9632166\tbest: 0.9639111 (12)\ttotal: 1m 12s\tremaining: 1h 25m 12s\n",
            "14:\ttest: 0.9632166\tbest: 0.9639111 (12)\ttotal: 1m 17s\tremaining: 1h 24m 48s\n",
            "15:\ttest: 0.9632960\tbest: 0.9639111 (12)\ttotal: 1m 22s\tremaining: 1h 24m 19s\n",
            "16:\ttest: 0.9633754\tbest: 0.9639111 (12)\ttotal: 1m 27s\tremaining: 1h 24m 4s\n",
            "17:\ttest: 0.9635778\tbest: 0.9639111 (12)\ttotal: 1m 31s\tremaining: 1h 23m 36s\n",
            "18:\ttest: 0.9635421\tbest: 0.9639111 (12)\ttotal: 1m 36s\tremaining: 1h 23m 26s\n",
            "19:\ttest: 0.9639111\tbest: 0.9639111 (19)\ttotal: 1m 41s\tremaining: 1h 23m 8s\n",
            "20:\ttest: 0.9638317\tbest: 0.9639111 (19)\ttotal: 1m 46s\tremaining: 1h 23m 3s\n",
            "21:\ttest: 0.9640778\tbest: 0.9640778 (21)\ttotal: 1m 52s\tremaining: 1h 23m 1s\n",
            "22:\ttest: 0.9639984\tbest: 0.9640778 (21)\ttotal: 1m 57s\tremaining: 1h 22m 51s\n",
            "23:\ttest: 0.9641572\tbest: 0.9641572 (23)\ttotal: 2m 1s\tremaining: 1h 22m 40s\n",
            "24:\ttest: 0.9642008\tbest: 0.9642008 (24)\ttotal: 2m 6s\tremaining: 1h 22m 27s\n",
            "25:\ttest: 0.9646135\tbest: 0.9646135 (25)\ttotal: 2m 11s\tremaining: 1h 22m 19s\n",
            "26:\ttest: 0.9649469\tbest: 0.9649469 (26)\ttotal: 2m 16s\tremaining: 1h 22m 6s\n",
            "27:\ttest: 0.9652366\tbest: 0.9652366 (27)\ttotal: 2m 21s\tremaining: 1h 21m 50s\n",
            "28:\ttest: 0.9654032\tbest: 0.9654032 (28)\ttotal: 2m 26s\tremaining: 1h 21m 54s\n",
            "29:\ttest: 0.9654032\tbest: 0.9654032 (28)\ttotal: 2m 31s\tremaining: 1h 21m 37s\n",
            "30:\ttest: 0.9654032\tbest: 0.9654032 (28)\ttotal: 2m 36s\tremaining: 1h 21m 43s\n",
            "31:\ttest: 0.9661414\tbest: 0.9661414 (31)\ttotal: 2m 41s\tremaining: 1h 21m 38s\n",
            "32:\ttest: 0.9662644\tbest: 0.9662644 (32)\ttotal: 2m 46s\tremaining: 1h 21m 23s\n",
            "33:\ttest: 0.9664311\tbest: 0.9664311 (33)\ttotal: 2m 51s\tremaining: 1h 21m 20s\n",
            "34:\ttest: 0.9666414\tbest: 0.9666414 (34)\ttotal: 2m 56s\tremaining: 1h 21m 11s\n",
            "35:\ttest: 0.9666414\tbest: 0.9666414 (34)\ttotal: 3m 1s\tremaining: 1h 21m 12s\n",
            "36:\ttest: 0.9668874\tbest: 0.9668874 (36)\ttotal: 3m 7s\tremaining: 1h 21m 11s\n",
            "37:\ttest: 0.9668874\tbest: 0.9668874 (36)\ttotal: 3m 12s\tremaining: 1h 21m 3s\n",
            "38:\ttest: 0.9670104\tbest: 0.9670104 (38)\ttotal: 3m 17s\tremaining: 1h 21m 3s\n",
            "39:\ttest: 0.9670104\tbest: 0.9670104 (38)\ttotal: 3m 22s\tremaining: 1h 20m 55s\n",
            "40:\ttest: 0.9674231\tbest: 0.9674231 (40)\ttotal: 3m 27s\tremaining: 1h 20m 48s\n",
            "41:\ttest: 0.9675541\tbest: 0.9675541 (41)\ttotal: 3m 32s\tremaining: 1h 20m 36s\n",
            "42:\ttest: 0.9675541\tbest: 0.9675541 (41)\ttotal: 3m 36s\tremaining: 1h 20m 27s\n",
            "43:\ttest: 0.9676771\tbest: 0.9676771 (43)\ttotal: 3m 41s\tremaining: 1h 20m 19s\n",
            "44:\ttest: 0.9677565\tbest: 0.9677565 (44)\ttotal: 3m 46s\tremaining: 1h 20m 14s\n",
            "45:\ttest: 0.9680025\tbest: 0.9680025 (45)\ttotal: 3m 51s\tremaining: 1h 20m 7s\n",
            "46:\ttest: 0.9680025\tbest: 0.9680025 (45)\ttotal: 3m 56s\tremaining: 1h 20m 5s\n",
            "47:\ttest: 0.9686176\tbest: 0.9686176 (47)\ttotal: 4m 2s\tremaining: 1h 20m 5s\n",
            "48:\ttest: 0.9689073\tbest: 0.9689073 (48)\ttotal: 4m 7s\tremaining: 1h 20m 3s\n",
            "49:\ttest: 0.9690740\tbest: 0.9690740 (49)\ttotal: 4m 12s\tremaining: 1h 19m 58s\n",
            "50:\ttest: 0.9690740\tbest: 0.9690740 (49)\ttotal: 4m 17s\tremaining: 1h 19m 49s\n",
            "51:\ttest: 0.9691970\tbest: 0.9691970 (51)\ttotal: 4m 22s\tremaining: 1h 19m 45s\n",
            "52:\ttest: 0.9691970\tbest: 0.9691970 (51)\ttotal: 4m 27s\tremaining: 1h 19m 42s\n",
            "53:\ttest: 0.9691970\tbest: 0.9691970 (51)\ttotal: 4m 32s\tremaining: 1h 19m 42s\n",
            "54:\ttest: 0.9693200\tbest: 0.9693200 (54)\ttotal: 4m 37s\tremaining: 1h 19m 34s\n",
            "55:\ttest: 0.9693200\tbest: 0.9693200 (54)\ttotal: 4m 42s\tremaining: 1h 19m 30s\n",
            "56:\ttest: 0.9698637\tbest: 0.9698637 (56)\ttotal: 4m 47s\tremaining: 1h 19m 19s\n",
            "57:\ttest: 0.9698200\tbest: 0.9698637 (56)\ttotal: 4m 52s\tremaining: 1h 19m 18s\n",
            "58:\ttest: 0.9700304\tbest: 0.9700304 (58)\ttotal: 4m 58s\tremaining: 1h 19m 18s\n",
            "59:\ttest: 0.9700304\tbest: 0.9700304 (58)\ttotal: 5m 3s\tremaining: 1h 19m 17s\n",
            "60:\ttest: 0.9700304\tbest: 0.9700304 (58)\ttotal: 5m 8s\tremaining: 1h 19m 9s\n",
            "61:\ttest: 0.9699510\tbest: 0.9700304 (58)\ttotal: 5m 13s\tremaining: 1h 19m\n",
            "62:\ttest: 0.9699510\tbest: 0.9700304 (58)\ttotal: 5m 18s\tremaining: 1h 18m 57s\n",
            "63:\ttest: 0.9699510\tbest: 0.9700304 (58)\ttotal: 5m 23s\tremaining: 1h 18m 54s\n",
            "64:\ttest: 0.9700740\tbest: 0.9700740 (64)\ttotal: 5m 29s\tremaining: 1h 18m 55s\n",
            "65:\ttest: 0.9700740\tbest: 0.9700740 (64)\ttotal: 5m 34s\tremaining: 1h 18m 52s\n",
            "66:\ttest: 0.9701970\tbest: 0.9701970 (66)\ttotal: 5m 39s\tremaining: 1h 18m 51s\n",
            "67:\ttest: 0.9701970\tbest: 0.9701970 (66)\ttotal: 5m 45s\tremaining: 1h 18m 50s\n",
            "68:\ttest: 0.9701970\tbest: 0.9701970 (66)\ttotal: 5m 50s\tremaining: 1h 18m 48s\n",
            "69:\ttest: 0.9701970\tbest: 0.9701970 (66)\ttotal: 5m 55s\tremaining: 1h 18m 44s\n",
            "70:\ttest: 0.9701970\tbest: 0.9701970 (66)\ttotal: 6m\tremaining: 1h 18m 43s\n",
            "71:\ttest: 0.9703200\tbest: 0.9703200 (71)\ttotal: 6m 6s\tremaining: 1h 18m 38s\n",
            "72:\ttest: 0.9704431\tbest: 0.9704431 (72)\ttotal: 6m 10s\tremaining: 1h 18m 28s\n",
            "73:\ttest: 0.9704431\tbest: 0.9704431 (72)\ttotal: 6m 16s\tremaining: 1h 18m 26s\n",
            "74:\ttest: 0.9704431\tbest: 0.9704431 (72)\ttotal: 6m 21s\tremaining: 1h 18m 24s\n",
            "75:\ttest: 0.9704431\tbest: 0.9704431 (72)\ttotal: 6m 26s\tremaining: 1h 18m 20s\n",
            "76:\ttest: 0.9705661\tbest: 0.9705661 (76)\ttotal: 6m 31s\tremaining: 1h 18m 15s\n",
            "77:\ttest: 0.9705661\tbest: 0.9705661 (76)\ttotal: 6m 36s\tremaining: 1h 18m 12s\n",
            "78:\ttest: 0.9705661\tbest: 0.9705661 (76)\ttotal: 6m 42s\tremaining: 1h 18m 9s\n",
            "79:\ttest: 0.9705661\tbest: 0.9705661 (76)\ttotal: 6m 47s\tremaining: 1h 18m 7s\n",
            "80:\ttest: 0.9704431\tbest: 0.9705661 (76)\ttotal: 6m 52s\tremaining: 1h 18m 3s\n",
            "81:\ttest: 0.9704431\tbest: 0.9705661 (76)\ttotal: 6m 57s\tremaining: 1h 17m 57s\n",
            "82:\ttest: 0.9704431\tbest: 0.9705661 (76)\ttotal: 7m 3s\tremaining: 1h 17m 54s\n",
            "83:\ttest: 0.9705661\tbest: 0.9705661 (76)\ttotal: 7m 8s\tremaining: 1h 17m 47s\n",
            "84:\ttest: 0.9703200\tbest: 0.9705661 (76)\ttotal: 7m 13s\tremaining: 1h 17m 44s\n",
            "85:\ttest: 0.9703200\tbest: 0.9705661 (76)\ttotal: 7m 18s\tremaining: 1h 17m 42s\n",
            "86:\ttest: 0.9701970\tbest: 0.9705661 (76)\ttotal: 7m 23s\tremaining: 1h 17m 37s\n",
            "Stopped by overfitting detector  (10 iterations wait)\n",
            "\n",
            "bestTest = 0.9705660951\n",
            "bestIteration = 76\n",
            "\n",
            "Shrink model to first 77 iterations.\n",
            "\n",
            "Model saved to: syn_catboost_model.cbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2396403861.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  topk = df.groupby(\"clean_row_id\", group_keys=False).apply(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics (Validation Set):\n",
            "Accuracy@1 : 0.9293\n",
            "Recall@3   : 0.9960\n",
            "MRR        : 0.9625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2396403861.py:58: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  mrr = df.groupby(\"clean_row_id\", group_keys=False).apply(reciprocal_rank).mean()\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from catboost import CatBoostRanker, Pool\n",
        "from typing import Tuple\n",
        "\n",
        "# Paths to files in Drive\n",
        "_DB_PATH = \"/content/drive/MyDrive/Colab Notebooks/database.db\"\n",
        "TEST_IDS = \"firm_held_test_ids.csv\"\n",
        "VAL_IDS = \"firm_held_val_ids.csv\"\n",
        "\n",
        "# Tuned hyperparameters\n",
        "_BEST_PARAMS = {\n",
        "    \"loss_function\": \"YetiRank\",\n",
        "    \"eval_metric\": \"NDCG:top=3\",\n",
        "    \"random_seed\": 42,\n",
        "    \"learning_rate\": 0.13275757957731918,\n",
        "    \"depth\": 6,\n",
        "    \"l2_leaf_reg\": 7.142519331365267,\n",
        "    \"random_strength\": 3.395785387976391,\n",
        "    \"min_data_in_leaf\": 84,\n",
        "    \"subsample\": 0.9048958560910838,\n",
        "    \"colsample_bylevel\": 0.511123337191838,\n",
        "    \"grow_policy\": \"Lossguide\",\n",
        "}\n",
        "\n",
        "\n",
        "def _compute_ranking_metrics(df: pd.DataFrame, k: int = 3):\n",
        "    \"\"\"\n",
        "    Compute Accuracy@1, Recall@k, and MRR for a ranking prediction dataframe.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Must contain columns ['clean_row_id', 'score', 'label']\n",
        "        k (int): The cutoff rank for recall@k\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float, float]: (Accuracy@1, Recall@k, MRR)\n",
        "    \"\"\"\n",
        "    # Accuracy@1\n",
        "    top1 = df.loc[df.groupby(\"clean_row_id\")[\"score\"].idxmax()]\n",
        "    acc1 = (top1[\"label\"] == 1).mean()\n",
        "\n",
        "    # Recall@k\n",
        "    topk = df.groupby(\"clean_row_id\", group_keys=False).apply(\n",
        "        lambda g: g.nlargest(k, \"score\")\n",
        "    )\n",
        "    recall_k = topk.groupby(\"clean_row_id\")[\"label\"].max().mean()\n",
        "\n",
        "    # MRR\n",
        "    def reciprocal_rank(g: pd.DataFrame) -> float:\n",
        "        labels_sorted = g.sort_values(\"score\", ascending=False)[\"label\"].to_numpy()\n",
        "        for rank, label in enumerate(labels_sorted, start=1):\n",
        "            if label == 1:\n",
        "                return 1.0 / rank\n",
        "        return 0.0\n",
        "\n",
        "    mrr = df.groupby(\"clean_row_id\", group_keys=False).apply(reciprocal_rank).mean()\n",
        "\n",
        "    return acc1, recall_k, mrr\n",
        "\n",
        "\n",
        "def _train_catboost_model(\n",
        "    parameters: dict,\n",
        "    train_df: pd.DataFrame,\n",
        "    val_df: pd.DataFrame,\n",
        "    n_rounds: int = 500,\n",
        "    model_output_path: str = \"catboost_model.cbm\",\n",
        ") -> CatBoostRanker:\n",
        "    \"\"\"\n",
        "    Trains a CatBoost ranking model using the provided training and validation data.\n",
        "\n",
        "    Args:\n",
        "        parameters (dict): Parameters for CatBoostRanker.\n",
        "        train_df (pd.DataFrame): Training data with label, group info, and features.\n",
        "        val_df (pd.DataFrame): Validation data with same structure.\n",
        "        n_rounds (int): Maximum number of boosting rounds.\n",
        "        model_output_path (str): File path to save the trained CatBoost model.\n",
        "\n",
        "    Returns:\n",
        "        CatBoostRanker: Trained CatBoost model.\n",
        "    \"\"\"\n",
        "    drop_cols = [\"label\", \"clean_row_id\", \"investor\", \"firm\", \"template_id\"]\n",
        "\n",
        "    # Train\n",
        "    train_group_sizes = train_df.groupby(\"clean_row_id\", sort=False).size().tolist()\n",
        "    train_group_id = np.repeat(np.arange(len(train_group_sizes)), train_group_sizes)\n",
        "\n",
        "    X_train = train_df.drop(columns=drop_cols)\n",
        "    y_train = train_df[\"label\"]\n",
        "    del train_df  # Free memory early\n",
        "\n",
        "    train_pool = Pool(data=X_train, label=y_train, group_id=train_group_id)\n",
        "    del X_train, y_train, train_group_id  # Free memory\n",
        "    gc.collect()  # Call garbage collector to be extra sure\n",
        "\n",
        "    # Validation\n",
        "    val_group_sizes = val_df.groupby(\"clean_row_id\", sort=False).size().tolist()\n",
        "    val_group_id = np.repeat(np.arange(len(val_group_sizes)), val_group_sizes)\n",
        "\n",
        "    X_val = val_df.drop(columns=drop_cols)\n",
        "    y_val = val_df[\"label\"]\n",
        "\n",
        "    val_pool = Pool(data=X_val, label=y_val, group_id=val_group_id)\n",
        "    del X_val, y_val, val_group_id  # Free memory\n",
        "    gc.collect()  # Call garbage collector to be extra sure\n",
        "\n",
        "    # Train model\n",
        "    model = CatBoostRanker(iterations=n_rounds, **parameters)\n",
        "    model.fit(\n",
        "        train_pool,\n",
        "        eval_set=val_pool,\n",
        "        early_stopping_rounds=10,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "    # Save model\n",
        "    model.save_model(model_output_path)\n",
        "    print(f\"\\nModel saved to: {model_output_path}\")\n",
        "\n",
        "    # Score model\n",
        "    val_df = val_df.copy()  # preserve original structure\n",
        "    val_df[\"score\"] = model.predict(val_pool)\n",
        "\n",
        "    acc1, recall3, mrr = _compute_ranking_metrics(val_df, k=3)\n",
        "\n",
        "    print(\"\\nEvaluation Metrics (Validation Set):\")\n",
        "    print(f\"Accuracy@1 : {acc1:.4f}\")\n",
        "    print(f\"Recall@3   : {recall3:.4f}\")\n",
        "    print(f\"MRR        : {mrr:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_syn_and_ran_model(\n",
        "    n_rounds: int = 1000,\n",
        "):\n",
        "    \"\"\"\n",
        "    Trains two CatBoost ranking models on pre-split data and saves them to disk.\n",
        "\n",
        "    The models are saved in `.cbm` format for compatibility with CatBoost's C++ inference engine.\n",
        "\n",
        "    Args:\n",
        "        n_rounds (int): Maximum number of boosting rounds for training (default: 1000).\n",
        "    \"\"\"\n",
        "    # Mount drive\n",
        "    import sys\n",
        "\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        from google.colab import drive\n",
        "\n",
        "        drive.mount(\"/content/drive\")\n",
        "\n",
        "    def train_model(\n",
        "        data_table: str, val_ids_path: str, test_ids_path: str, model_path: str\n",
        "    ):\n",
        "        print(f\"Training model: {model_path}\")\n",
        "        # Get ids\n",
        "        val_ids = (\n",
        "            pd.read_csv(val_ids_path)[\"val_ids\"].dropna().astype(int).tolist()\n",
        "        )\n",
        "        test_ids = (\n",
        "            pd.read_csv(test_ids_path)[\"test_ids\"].dropna().astype(int).tolist()\n",
        "        )\n",
        "\n",
        "        # Get data\n",
        "        chunk_size = 100000\n",
        "        chunks = []\n",
        "        with sqlite3.connect(_DB_PATH) as conn:\n",
        "            for chunk in pd.read_sql_query(f\"SELECT * FROM {data_table}\", conn, chunksize=chunk_size):\n",
        "                chunks.append(chunk)\n",
        "            full_df = pd.concat(chunks, ignore_index=True)\n",
        "\n",
        "        # Split the set\n",
        "        val_ids_set = set(val_ids)\n",
        "        test_ids_set = set(test_ids)\n",
        "        excluded_ids = val_ids_set | test_ids_set\n",
        "        val_df = full_df[full_df[\"clean_row_id\"].isin(val_ids_set)]\n",
        "        full_df = full_df[~full_df[\"clean_row_id\"].isin(excluded_ids)]\n",
        "\n",
        "        # Train model\n",
        "        return _train_catboost_model(\n",
        "            _BEST_PARAMS, full_df, val_df, n_rounds, model_path\n",
        "        )\n",
        "\n",
        "    # Start with standard\n",
        "    syn = train_model(\"feature_matrix\", VAL_IDS, TEST_IDS, \"syn_catboost_model.cbm\")\n",
        "\n",
        "    return syn\n",
        "\n",
        "syn = train_syn_and_ran_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEn4CnKNqRfG"
      },
      "source": [
        "Ok Models are trained. Synthetic case performed significantly better in validation with ~93% Accuracy@1 whereas the placebo set achieved ~45% Accuracy@1.\n",
        "\n",
        "Let's run the test set to be sure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyZF3hf3qRfH",
        "outputId": "ae91a121-9b5c-442a-b6a9-1516faace56a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2396403861.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  topk = df.groupby(\"clean_row_id\", group_keys=False).apply(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics (Unseen Firms Test Set):\n",
            "Accuracy@1 : 0.9292\n",
            "Recall@3   : 0.9970\n",
            "MRR        : 0.9618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2396403861.py:58: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  mrr = df.groupby(\"clean_row_id\", group_keys=False).apply(reciprocal_rank).mean()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.9292), np.float64(0.997), np.float64(0.961785))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "def evaluate_on_test(model, test_ids_path, data_table: str, label=\"\"):\n",
        "    # Load test IDs\n",
        "    test_ids = pd.read_csv(test_ids_path)[\"test_ids\"].dropna().astype(int).tolist()\n",
        "    test_ids_set = set(test_ids)\n",
        "\n",
        "    # Load test rows from DB\n",
        "    with sqlite3.connect(_DB_PATH) as conn:\n",
        "        test_df = pd.read_sql_query(\n",
        "            f\"SELECT * FROM {data_table} WHERE clean_row_id IN ({','.join(map(str, test_ids_set))})\",\n",
        "            conn,\n",
        "        )\n",
        "\n",
        "    # Drop non-feature columns\n",
        "    drop_cols = [\"label\", \"clean_row_id\", \"investor\", \"firm\", \"template_id\"]\n",
        "    group_sizes = test_df.groupby(\"clean_row_id\", sort=False).size().tolist()\n",
        "    group_id = np.repeat(np.arange(len(group_sizes)), group_sizes)\n",
        "\n",
        "    X_test = test_df.drop(columns=drop_cols)\n",
        "    y_test = test_df[\"label\"]\n",
        "\n",
        "    test_pool = Pool(data=X_test, label=y_test, group_id=group_id)\n",
        "    test_df[\"score\"] = model.predict(test_pool)\n",
        "\n",
        "    acc1, recall3, mrr = _compute_ranking_metrics(test_df, k=3)\n",
        "    print(f\"\\nEvaluation Metrics ({label} Test Set):\")\n",
        "    print(f\"Accuracy@1 : {acc1:.4f}\")\n",
        "    print(f\"Recall@3   : {recall3:.4f}\")\n",
        "    print(f\"MRR        : {mrr:.4f}\")\n",
        "\n",
        "    return acc1, recall3, mrr\n",
        "\n",
        "# Evaluate both models on their test sets\n",
        "evaluate_on_test(syn, TEST_IDS, \"feature_matrix\", label=\"Unseen Firms\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}