{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjE0M1VsiF7a"
      },
      "source": [
        "# Placebo Testing Synthetic Investors\n",
        "\n",
        "The standard feature matrix table will contain synthetic investors that were generated in a statistically faithful approach that attempts to maintain global statistics. The complex set will contain synthetic investors that were randomly duplicated from existing investors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNrhVNxUiAcx",
        "outputId": "04b8bf16-003b-43bb-a9ba-3a26a06da35d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sqlalchemy\n",
            "  Downloading sqlalchemy-2.0.43-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting greenlet>=1 (from sqlalchemy)\n",
            "  Downloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (4.15.0)\n",
            "Downloading sqlalchemy-2.0.43-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (607 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m607.6/607.6 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: greenlet, sqlalchemy\n",
            "Successfully installed greenlet-3.2.4 sqlalchemy-2.0.43\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting graphviz (from catboost)\n",
            "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: graphviz, catboost\n",
            "Successfully installed catboost-1.2.8 graphviz-0.21\n"
          ]
        }
      ],
      "source": [
        "!pip install sqlalchemy\n",
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETPXIgXdjtD0",
        "outputId": "426ca9d1-f571-434f-ae0c-59ce85454edc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Training model: syn_catboost_model.cbm\n",
            "0:\ttest: 0.9558808\tbest: 0.9558808 (0)\ttotal: 5.12s\tremaining: 1h 25m 13s\n",
            "1:\ttest: 0.9593632\tbest: 0.9593632 (1)\ttotal: 10.9s\tremaining: 1h 31m 2s\n",
            "2:\ttest: 0.9617114\tbest: 0.9617114 (2)\ttotal: 16.6s\tremaining: 1h 32m 5s\n",
            "3:\ttest: 0.9630054\tbest: 0.9630054 (3)\ttotal: 21.9s\tremaining: 1h 30m 45s\n",
            "4:\ttest: 0.9633745\tbest: 0.9633745 (4)\ttotal: 27.3s\tremaining: 1h 30m 36s\n",
            "5:\ttest: 0.9629292\tbest: 0.9633745 (4)\ttotal: 33.2s\tremaining: 1h 31m 40s\n",
            "6:\ttest: 0.9628455\tbest: 0.9633745 (4)\ttotal: 38.5s\tremaining: 1h 30m 57s\n",
            "7:\ttest: 0.9632908\tbest: 0.9633745 (4)\ttotal: 44.3s\tremaining: 1h 31m 29s\n",
            "8:\ttest: 0.9633745\tbest: 0.9633745 (4)\ttotal: 49.3s\tremaining: 1h 30m 31s\n",
            "9:\ttest: 0.9635686\tbest: 0.9635686 (9)\ttotal: 54.6s\tremaining: 1h 30m 3s\n",
            "10:\ttest: 0.9638465\tbest: 0.9638465 (10)\ttotal: 1m\tremaining: 1h 30m 31s\n",
            "11:\ttest: 0.9640482\tbest: 0.9640482 (11)\ttotal: 1m 6s\tremaining: 1h 30m 40s\n",
            "12:\ttest: 0.9643679\tbest: 0.9643679 (12)\ttotal: 1m 11s\tremaining: 1h 30m 21s\n",
            "13:\ttest: 0.9640558\tbest: 0.9643679 (12)\ttotal: 1m 16s\tremaining: 1h 30m 13s\n",
            "14:\ttest: 0.9646457\tbest: 0.9646457 (14)\ttotal: 1m 22s\tremaining: 1h 29m 56s\n",
            "15:\ttest: 0.9645696\tbest: 0.9646457 (14)\ttotal: 1m 27s\tremaining: 1h 29m 50s\n",
            "16:\ttest: 0.9645010\tbest: 0.9646457 (14)\ttotal: 1m 32s\tremaining: 1h 29m 32s\n",
            "17:\ttest: 0.9645010\tbest: 0.9646457 (14)\ttotal: 1m 38s\tremaining: 1h 29m 13s\n",
            "18:\ttest: 0.9641052\tbest: 0.9646457 (14)\ttotal: 1m 43s\tremaining: 1h 29m 5s\n",
            "19:\ttest: 0.9641052\tbest: 0.9646457 (14)\ttotal: 1m 48s\tremaining: 1h 28m 58s\n",
            "20:\ttest: 0.9643830\tbest: 0.9646457 (14)\ttotal: 1m 54s\tremaining: 1h 28m 49s\n",
            "21:\ttest: 0.9646190\tbest: 0.9646457 (14)\ttotal: 1m 59s\tremaining: 1h 28m 39s\n",
            "22:\ttest: 0.9651328\tbest: 0.9651328 (22)\ttotal: 2m 4s\tremaining: 1h 28m 17s\n",
            "23:\ttest: 0.9653764\tbest: 0.9653764 (23)\ttotal: 2m 9s\tremaining: 1h 28m 4s\n",
            "24:\ttest: 0.9655362\tbest: 0.9655362 (24)\ttotal: 2m 14s\tremaining: 1h 27m 44s\n",
            "25:\ttest: 0.9664040\tbest: 0.9664040 (25)\ttotal: 2m 20s\tremaining: 1h 27m 26s\n",
            "26:\ttest: 0.9668341\tbest: 0.9668341 (26)\ttotal: 2m 25s\tremaining: 1h 27m 33s\n",
            "27:\ttest: 0.9670282\tbest: 0.9670282 (27)\ttotal: 2m 31s\tremaining: 1h 27m 29s\n",
            "28:\ttest: 0.9675002\tbest: 0.9675002 (28)\ttotal: 2m 36s\tremaining: 1h 27m 12s\n",
            "29:\ttest: 0.9678960\tbest: 0.9678960 (29)\ttotal: 2m 41s\tremaining: 1h 26m 55s\n",
            "30:\ttest: 0.9683337\tbest: 0.9683337 (30)\ttotal: 2m 46s\tremaining: 1h 26m 50s\n",
            "31:\ttest: 0.9683680\tbest: 0.9683680 (31)\ttotal: 2m 52s\tremaining: 1h 26m 49s\n",
            "32:\ttest: 0.9691596\tbest: 0.9691596 (32)\ttotal: 2m 57s\tremaining: 1h 26m 36s\n",
            "33:\ttest: 0.9691596\tbest: 0.9691596 (32)\ttotal: 3m 2s\tremaining: 1h 26m 34s\n",
            "34:\ttest: 0.9692776\tbest: 0.9692776 (34)\ttotal: 3m 8s\tremaining: 1h 26m 38s\n",
            "35:\ttest: 0.9695136\tbest: 0.9695136 (35)\ttotal: 3m 14s\tremaining: 1h 26m 46s\n",
            "36:\ttest: 0.9699094\tbest: 0.9699094 (36)\ttotal: 3m 20s\tremaining: 1h 26m 48s\n",
            "37:\ttest: 0.9699094\tbest: 0.9699094 (36)\ttotal: 3m 25s\tremaining: 1h 26m 50s\n",
            "38:\ttest: 0.9701454\tbest: 0.9701454 (38)\ttotal: 3m 31s\tremaining: 1h 26m 53s\n",
            "39:\ttest: 0.9705412\tbest: 0.9705412 (39)\ttotal: 3m 36s\tremaining: 1h 26m 42s\n",
            "40:\ttest: 0.9706249\tbest: 0.9706249 (40)\ttotal: 3m 42s\tremaining: 1h 26m 46s\n",
            "41:\ttest: 0.9707011\tbest: 0.9707011 (41)\ttotal: 3m 48s\tremaining: 1h 26m 44s\n",
            "42:\ttest: 0.9707011\tbest: 0.9707011 (41)\ttotal: 3m 54s\tremaining: 1h 26m 48s\n",
            "43:\ttest: 0.9710550\tbest: 0.9710550 (43)\ttotal: 3m 59s\tremaining: 1h 26m 40s\n",
            "44:\ttest: 0.9711730\tbest: 0.9711730 (44)\ttotal: 4m 4s\tremaining: 1h 26m 34s\n",
            "45:\ttest: 0.9715688\tbest: 0.9715688 (45)\ttotal: 4m 10s\tremaining: 1h 26m 33s\n",
            "46:\ttest: 0.9716868\tbest: 0.9716868 (46)\ttotal: 4m 15s\tremaining: 1h 26m 30s\n",
            "47:\ttest: 0.9717287\tbest: 0.9717287 (47)\ttotal: 4m 21s\tremaining: 1h 26m 21s\n",
            "48:\ttest: 0.9722007\tbest: 0.9722007 (48)\ttotal: 4m 27s\tremaining: 1h 26m 27s\n",
            "49:\ttest: 0.9720827\tbest: 0.9722007 (48)\ttotal: 4m 33s\tremaining: 1h 26m 29s\n",
            "50:\ttest: 0.9719647\tbest: 0.9722007 (48)\ttotal: 4m 39s\tremaining: 1h 26m 31s\n",
            "51:\ttest: 0.9719228\tbest: 0.9722007 (48)\ttotal: 4m 44s\tremaining: 1h 26m 30s\n",
            "52:\ttest: 0.9715688\tbest: 0.9722007 (48)\ttotal: 4m 50s\tremaining: 1h 26m 21s\n",
            "53:\ttest: 0.9716868\tbest: 0.9722007 (48)\ttotal: 4m 55s\tremaining: 1h 26m 22s\n",
            "54:\ttest: 0.9715270\tbest: 0.9722007 (48)\ttotal: 5m 1s\tremaining: 1h 26m 20s\n",
            "55:\ttest: 0.9715688\tbest: 0.9722007 (48)\ttotal: 5m 7s\tremaining: 1h 26m 22s\n",
            "56:\ttest: 0.9715688\tbest: 0.9722007 (48)\ttotal: 5m 13s\tremaining: 1h 26m 21s\n",
            "57:\ttest: 0.9715688\tbest: 0.9722007 (48)\ttotal: 5m 18s\tremaining: 1h 26m 14s\n",
            "58:\ttest: 0.9715688\tbest: 0.9722007 (48)\ttotal: 5m 24s\tremaining: 1h 26m 12s\n",
            "Stopped by overfitting detector  (10 iterations wait)\n",
            "\n",
            "bestTest = 0.9722006511\n",
            "bestIteration = 48\n",
            "\n",
            "Shrink model to first 49 iterations.\n",
            "\n",
            "Model saved to: syn_catboost_model.cbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1406598767.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  topk = df.groupby(\"clean_row_id\", group_keys=False).apply(\n",
            "/tmp/ipython-input-1406598767.py:58: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  mrr = df.groupby(\"clean_row_id\", group_keys=False).apply(reciprocal_rank).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics (Validation Set):\n",
            "Accuracy@1 : 0.9332\n",
            "Recall@3   : 0.9965\n",
            "MRR        : 0.9644\n",
            "Training model: ran_catboost_model.cbm\n",
            "0:\ttest: 0.6306195\tbest: 0.6306195 (0)\ttotal: 1.57s\tremaining: 26m 8s\n",
            "1:\ttest: 0.6395205\tbest: 0.6395205 (1)\ttotal: 3.19s\tremaining: 26m 31s\n",
            "2:\ttest: 0.6422610\tbest: 0.6422610 (2)\ttotal: 4.9s\tremaining: 27m 9s\n",
            "3:\ttest: 0.6364604\tbest: 0.6422610 (2)\ttotal: 6.58s\tremaining: 27m 17s\n",
            "4:\ttest: 0.6344127\tbest: 0.6422610 (2)\ttotal: 8.33s\tremaining: 27m 37s\n",
            "5:\ttest: 0.6308731\tbest: 0.6422610 (2)\ttotal: 9.91s\tremaining: 27m 22s\n",
            "6:\ttest: 0.6441716\tbest: 0.6441716 (6)\ttotal: 11.6s\tremaining: 27m 18s\n",
            "7:\ttest: 0.6455189\tbest: 0.6455189 (7)\ttotal: 13.2s\tremaining: 27m 11s\n",
            "8:\ttest: 0.6426034\tbest: 0.6455189 (7)\ttotal: 14.9s\tremaining: 27m 17s\n",
            "9:\ttest: 0.6450812\tbest: 0.6455189 (7)\ttotal: 16.5s\tremaining: 27m 18s\n",
            "10:\ttest: 0.6450812\tbest: 0.6455189 (7)\ttotal: 18.2s\tremaining: 27m 12s\n",
            "11:\ttest: 0.6464209\tbest: 0.6464209 (11)\ttotal: 19.9s\tremaining: 27m 19s\n",
            "12:\ttest: 0.6585053\tbest: 0.6585053 (12)\ttotal: 21.6s\tremaining: 27m 19s\n",
            "13:\ttest: 0.6644466\tbest: 0.6644466 (13)\ttotal: 23.3s\tremaining: 27m 20s\n",
            "14:\ttest: 0.6677921\tbest: 0.6677921 (14)\ttotal: 25s\tremaining: 27m 19s\n",
            "15:\ttest: 0.6726640\tbest: 0.6726640 (15)\ttotal: 26.6s\tremaining: 27m 15s\n",
            "16:\ttest: 0.6906478\tbest: 0.6906478 (16)\ttotal: 28.2s\tremaining: 27m 13s\n",
            "17:\ttest: 0.6895440\tbest: 0.6906478 (16)\ttotal: 29.9s\tremaining: 27m 11s\n",
            "18:\ttest: 0.6901340\tbest: 0.6906478 (16)\ttotal: 31.5s\tremaining: 27m 7s\n",
            "19:\ttest: 0.6904194\tbest: 0.6906478 (16)\ttotal: 33.1s\tremaining: 27m 3s\n",
            "20:\ttest: 0.6908571\tbest: 0.6908571 (20)\ttotal: 34.8s\tremaining: 27m 4s\n",
            "21:\ttest: 0.6912872\tbest: 0.6912872 (21)\ttotal: 36.3s\tremaining: 26m 55s\n",
            "22:\ttest: 0.6939666\tbest: 0.6939666 (22)\ttotal: 38.1s\tremaining: 26m 56s\n",
            "23:\ttest: 0.6940846\tbest: 0.6940846 (23)\ttotal: 39.8s\tremaining: 26m 58s\n",
            "24:\ttest: 0.6936127\tbest: 0.6940846 (23)\ttotal: 41.5s\tremaining: 26m 59s\n",
            "25:\ttest: 0.6936545\tbest: 0.6940846 (23)\ttotal: 43.3s\tremaining: 27m\n",
            "26:\ttest: 0.6940085\tbest: 0.6940846 (23)\ttotal: 44.9s\tremaining: 26m 58s\n",
            "27:\ttest: 0.6936888\tbest: 0.6940846 (23)\ttotal: 46.5s\tremaining: 26m 55s\n",
            "28:\ttest: 0.6944386\tbest: 0.6944386 (28)\ttotal: 48.2s\tremaining: 26m 55s\n",
            "29:\ttest: 0.6942026\tbest: 0.6944386 (28)\ttotal: 49.9s\tremaining: 26m 52s\n",
            "30:\ttest: 0.6936051\tbest: 0.6944386 (28)\ttotal: 51.6s\tremaining: 26m 53s\n",
            "31:\ttest: 0.6946670\tbest: 0.6946670 (31)\ttotal: 53.3s\tremaining: 26m 53s\n",
            "32:\ttest: 0.6945984\tbest: 0.6946670 (31)\ttotal: 55.1s\tremaining: 26m 53s\n",
            "33:\ttest: 0.6948763\tbest: 0.6948763 (33)\ttotal: 56.8s\tremaining: 26m 52s\n",
            "34:\ttest: 0.6953482\tbest: 0.6953482 (34)\ttotal: 58.4s\tremaining: 26m 50s\n",
            "35:\ttest: 0.6949106\tbest: 0.6953482 (34)\ttotal: 1m\tremaining: 26m 50s\n",
            "36:\ttest: 0.6949106\tbest: 0.6953482 (34)\ttotal: 1m 1s\tremaining: 26m 50s\n",
            "37:\ttest: 0.6957022\tbest: 0.6957022 (37)\ttotal: 1m 3s\tremaining: 26m 45s\n",
            "38:\ttest: 0.6962160\tbest: 0.6962160 (38)\ttotal: 1m 5s\tremaining: 26m 44s\n",
            "39:\ttest: 0.6960562\tbest: 0.6962160 (38)\ttotal: 1m 6s\tremaining: 26m 40s\n",
            "40:\ttest: 0.6961742\tbest: 0.6962160 (38)\ttotal: 1m 8s\tremaining: 26m 35s\n",
            "41:\ttest: 0.6962922\tbest: 0.6962922 (41)\ttotal: 1m 9s\tremaining: 26m 36s\n",
            "42:\ttest: 0.6964939\tbest: 0.6964939 (42)\ttotal: 1m 11s\tremaining: 26m 36s\n",
            "43:\ttest: 0.6966118\tbest: 0.6966118 (43)\ttotal: 1m 13s\tremaining: 26m 35s\n",
            "44:\ttest: 0.6968973\tbest: 0.6968973 (44)\ttotal: 1m 15s\tremaining: 26m 33s\n",
            "45:\ttest: 0.6968973\tbest: 0.6968973 (44)\ttotal: 1m 16s\tremaining: 26m 33s\n",
            "46:\ttest: 0.6970914\tbest: 0.6970914 (46)\ttotal: 1m 18s\tremaining: 26m 31s\n",
            "47:\ttest: 0.6968211\tbest: 0.6970914 (46)\ttotal: 1m 20s\tremaining: 26m 29s\n",
            "48:\ttest: 0.6976471\tbest: 0.6976471 (48)\ttotal: 1m 21s\tremaining: 26m 29s\n",
            "49:\ttest: 0.6976128\tbest: 0.6976471 (48)\ttotal: 1m 23s\tremaining: 26m 27s\n",
            "50:\ttest: 0.6980086\tbest: 0.6980086 (50)\ttotal: 1m 25s\tremaining: 26m 27s\n",
            "51:\ttest: 0.6986404\tbest: 0.6986404 (51)\ttotal: 1m 26s\tremaining: 26m 24s\n",
            "52:\ttest: 0.6986404\tbest: 0.6986404 (51)\ttotal: 1m 28s\tremaining: 26m 23s\n",
            "53:\ttest: 0.6990781\tbest: 0.6990781 (53)\ttotal: 1m 30s\tremaining: 26m 23s\n",
            "54:\ttest: 0.6990705\tbest: 0.6990781 (53)\ttotal: 1m 32s\tremaining: 26m 22s\n",
            "55:\ttest: 0.6998203\tbest: 0.6998203 (55)\ttotal: 1m 33s\tremaining: 26m 21s\n",
            "56:\ttest: 0.6997023\tbest: 0.6998203 (55)\ttotal: 1m 35s\tremaining: 26m 21s\n",
            "57:\ttest: 0.6998622\tbest: 0.6998622 (57)\ttotal: 1m 37s\tremaining: 26m 19s\n",
            "58:\ttest: 0.7002580\tbest: 0.7002580 (58)\ttotal: 1m 38s\tremaining: 26m 15s\n",
            "59:\ttest: 0.7002161\tbest: 0.7002580 (58)\ttotal: 1m 40s\tremaining: 26m 12s\n",
            "60:\ttest: 0.7002161\tbest: 0.7002580 (58)\ttotal: 1m 42s\tremaining: 26m 11s\n",
            "61:\ttest: 0.7001400\tbest: 0.7002580 (58)\ttotal: 1m 43s\tremaining: 26m 9s\n",
            "62:\ttest: 0.7001400\tbest: 0.7002580 (58)\ttotal: 1m 45s\tremaining: 26m 8s\n",
            "63:\ttest: 0.6995919\tbest: 0.7002580 (58)\ttotal: 1m 47s\tremaining: 26m 8s\n",
            "64:\ttest: 0.6998279\tbest: 0.7002580 (58)\ttotal: 1m 48s\tremaining: 26m 6s\n",
            "65:\ttest: 0.6999459\tbest: 0.7002580 (58)\ttotal: 1m 50s\tremaining: 26m 4s\n",
            "66:\ttest: 0.7010496\tbest: 0.7010496 (66)\ttotal: 1m 52s\tremaining: 26m 2s\n",
            "67:\ttest: 0.7005777\tbest: 0.7010496 (66)\ttotal: 1m 53s\tremaining: 26m\n",
            "68:\ttest: 0.7006614\tbest: 0.7010496 (66)\ttotal: 1m 55s\tremaining: 25m 58s\n",
            "69:\ttest: 0.7010572\tbest: 0.7010572 (69)\ttotal: 1m 57s\tremaining: 25m 57s\n",
            "70:\ttest: 0.7009392\tbest: 0.7010572 (69)\ttotal: 1m 58s\tremaining: 25m 56s\n",
            "71:\ttest: 0.7006614\tbest: 0.7010572 (69)\ttotal: 2m\tremaining: 25m 55s\n",
            "72:\ttest: 0.7007375\tbest: 0.7010572 (69)\ttotal: 2m 2s\tremaining: 25m 55s\n",
            "73:\ttest: 0.7006195\tbest: 0.7010572 (69)\ttotal: 2m 4s\tremaining: 25m 53s\n",
            "74:\ttest: 0.7002656\tbest: 0.7010572 (69)\ttotal: 2m 5s\tremaining: 25m 51s\n",
            "75:\ttest: 0.7005015\tbest: 0.7010572 (69)\ttotal: 2m 7s\tremaining: 25m 50s\n",
            "76:\ttest: 0.7000714\tbest: 0.7010572 (69)\ttotal: 2m 9s\tremaining: 25m 49s\n",
            "77:\ttest: 0.7000296\tbest: 0.7010572 (69)\ttotal: 2m 10s\tremaining: 25m 48s\n",
            "78:\ttest: 0.6993978\tbest: 0.7010572 (69)\ttotal: 2m 12s\tremaining: 25m 46s\n",
            "79:\ttest: 0.6996756\tbest: 0.7010572 (69)\ttotal: 2m 14s\tremaining: 25m 44s\n",
            "Stopped by overfitting detector  (10 iterations wait)\n",
            "\n",
            "bestTest = 0.7010572202\n",
            "bestIteration = 69\n",
            "\n",
            "Shrink model to first 70 iterations.\n",
            "\n",
            "Model saved to: ran_catboost_model.cbm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1406598767.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  topk = df.groupby(\"clean_row_id\", group_keys=False).apply(\n",
            "/tmp/ipython-input-1406598767.py:58: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  mrr = df.groupby(\"clean_row_id\", group_keys=False).apply(reciprocal_rank).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics (Validation Set):\n",
            "Accuracy@1 : 0.4556\n",
            "Recall@3   : 0.8667\n",
            "MRR        : 0.6625\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from catboost import CatBoostRanker, Pool\n",
        "from typing import Tuple\n",
        "\n",
        "# Paths to files in Drive\n",
        "_DB_PATH = \"/content/drive/MyDrive/Colab Notebooks/database.db\"\n",
        "TEST_IDS = \"test_ids.csv\"\n",
        "VAL_IDS = \"val_ids.csv\"\n",
        "\n",
        "# Tuned hyperparameters\n",
        "_BEST_PARAMS = {\n",
        "    \"loss_function\": \"YetiRank\",\n",
        "    \"eval_metric\": \"NDCG:top=3\",\n",
        "    \"random_seed\": 42,\n",
        "    \"learning_rate\": 0.13275757957731918,\n",
        "    \"depth\": 6,\n",
        "    \"l2_leaf_reg\": 7.142519331365267,\n",
        "    \"random_strength\": 3.395785387976391,\n",
        "    \"min_data_in_leaf\": 84,\n",
        "    \"subsample\": 0.9048958560910838,\n",
        "    \"colsample_bylevel\": 0.511123337191838,\n",
        "    \"grow_policy\": \"Lossguide\",\n",
        "}\n",
        "\n",
        "\n",
        "def _compute_ranking_metrics(df: pd.DataFrame, k: int = 3):\n",
        "    \"\"\"\n",
        "    Compute Accuracy@1, Recall@k, and MRR for a ranking prediction dataframe.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Must contain columns ['clean_row_id', 'score', 'label']\n",
        "        k (int): The cutoff rank for recall@k\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float, float]: (Accuracy@1, Recall@k, MRR)\n",
        "    \"\"\"\n",
        "    # Accuracy@1\n",
        "    top1 = df.loc[df.groupby(\"clean_row_id\")[\"score\"].idxmax()]\n",
        "    acc1 = (top1[\"label\"] == 1).mean()\n",
        "\n",
        "    # Recall@k\n",
        "    topk = df.groupby(\"clean_row_id\", group_keys=False).apply(\n",
        "        lambda g: g.nlargest(k, \"score\")\n",
        "    )\n",
        "    recall_k = topk.groupby(\"clean_row_id\")[\"label\"].max().mean()\n",
        "\n",
        "    # MRR\n",
        "    def reciprocal_rank(g: pd.DataFrame) -> float:\n",
        "        labels_sorted = g.sort_values(\"score\", ascending=False)[\"label\"].to_numpy()\n",
        "        for rank, label in enumerate(labels_sorted, start=1):\n",
        "            if label == 1:\n",
        "                return 1.0 / rank\n",
        "        return 0.0\n",
        "\n",
        "    mrr = df.groupby(\"clean_row_id\", group_keys=False).apply(reciprocal_rank).mean()\n",
        "\n",
        "    return acc1, recall_k, mrr\n",
        "\n",
        "\n",
        "def _train_catboost_model(\n",
        "    parameters: dict,\n",
        "    train_df: pd.DataFrame,\n",
        "    val_df: pd.DataFrame,\n",
        "    n_rounds: int = 500,\n",
        "    model_output_path: str = \"catboost_model.cbm\",\n",
        ") -> CatBoostRanker:\n",
        "    \"\"\"\n",
        "    Trains a CatBoost ranking model using the provided training and validation data.\n",
        "\n",
        "    Args:\n",
        "        parameters (dict): Parameters for CatBoostRanker.\n",
        "        train_df (pd.DataFrame): Training data with label, group info, and features.\n",
        "        val_df (pd.DataFrame): Validation data with same structure.\n",
        "        n_rounds (int): Maximum number of boosting rounds.\n",
        "        model_output_path (str): File path to save the trained CatBoost model.\n",
        "\n",
        "    Returns:\n",
        "        CatBoostRanker: Trained CatBoost model.\n",
        "    \"\"\"\n",
        "    drop_cols = [\"label\", \"clean_row_id\", \"investor\", \"firm\", \"template_id\"]\n",
        "\n",
        "    # Train\n",
        "    train_group_sizes = train_df.groupby(\"clean_row_id\", sort=False).size().tolist()\n",
        "    train_group_id = np.repeat(np.arange(len(train_group_sizes)), train_group_sizes)\n",
        "\n",
        "    X_train = train_df.drop(columns=drop_cols)\n",
        "    y_train = train_df[\"label\"]\n",
        "    del train_df  # Free memory early\n",
        "\n",
        "    train_pool = Pool(data=X_train, label=y_train, group_id=train_group_id)\n",
        "    del X_train, y_train, train_group_id  # Free memory\n",
        "    gc.collect()  # Call garbage collector to be extra sure\n",
        "\n",
        "    # Validation\n",
        "    val_group_sizes = val_df.groupby(\"clean_row_id\", sort=False).size().tolist()\n",
        "    val_group_id = np.repeat(np.arange(len(val_group_sizes)), val_group_sizes)\n",
        "\n",
        "    X_val = val_df.drop(columns=drop_cols)\n",
        "    y_val = val_df[\"label\"]\n",
        "\n",
        "    val_pool = Pool(data=X_val, label=y_val, group_id=val_group_id)\n",
        "    del X_val, y_val, val_group_id  # Free memory\n",
        "    gc.collect()  # Call garbage collector to be extra sure\n",
        "\n",
        "    # Train model\n",
        "    model = CatBoostRanker(iterations=n_rounds, **parameters)\n",
        "    model.fit(\n",
        "        train_pool,\n",
        "        eval_set=val_pool,\n",
        "        early_stopping_rounds=10,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "    # Save model\n",
        "    model.save_model(model_output_path)\n",
        "    print(f\"\\nModel saved to: {model_output_path}\")\n",
        "\n",
        "    # Score model\n",
        "    val_df = val_df.copy()  # preserve original structure\n",
        "    val_df[\"score\"] = model.predict(val_pool)\n",
        "\n",
        "    acc1, recall3, mrr = _compute_ranking_metrics(val_df, k=3)\n",
        "\n",
        "    print(\"\\nEvaluation Metrics (Validation Set):\")\n",
        "    print(f\"Accuracy@1 : {acc1:.4f}\")\n",
        "    print(f\"Recall@3   : {recall3:.4f}\")\n",
        "    print(f\"MRR        : {mrr:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_syn_and_ran_model(\n",
        "    n_rounds: int = 1000,\n",
        "):\n",
        "    \"\"\"\n",
        "    Trains two CatBoost ranking models on pre-split data and saves them to disk.\n",
        "\n",
        "    The models are saved in `.cbm` format for compatibility with CatBoost's C++ inference engine.\n",
        "\n",
        "    Args:\n",
        "        n_rounds (int): Maximum number of boosting rounds for training (default: 1000).\n",
        "    \"\"\"\n",
        "    # Mount drive\n",
        "    import sys\n",
        "\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        from google.colab import drive\n",
        "\n",
        "        drive.mount(\"/content/drive\")\n",
        "\n",
        "    def train_model(\n",
        "        data_table: str, val_ids_path: str, test_ids_path: str, model_path: str\n",
        "    ):\n",
        "        print(f\"Training model: {model_path}\")\n",
        "        # Get ids\n",
        "        val_ids = (\n",
        "            pd.read_csv(val_ids_path)[\"val_ids\"].dropna().astype(int).tolist()\n",
        "        )\n",
        "        test_ids = (\n",
        "            pd.read_csv(test_ids_path)[\"test_ids\"].dropna().astype(int).tolist()\n",
        "        )\n",
        "\n",
        "        # Get data\n",
        "        chunk_size = 100000\n",
        "        chunks = []\n",
        "        with sqlite3.connect(_DB_PATH) as conn:\n",
        "            for chunk in pd.read_sql_query(f\"SELECT * FROM {data_table}\", conn, chunksize=chunk_size):\n",
        "                chunks.append(chunk)\n",
        "            full_df = pd.concat(chunks, ignore_index=True)\n",
        "\n",
        "        # Split the set\n",
        "        val_ids_set = set(val_ids)\n",
        "        test_ids_set = set(test_ids)\n",
        "        excluded_ids = val_ids_set | test_ids_set\n",
        "        val_df = full_df[full_df[\"clean_row_id\"].isin(val_ids_set)]\n",
        "        full_df = full_df[~full_df[\"clean_row_id\"].isin(excluded_ids)]\n",
        "\n",
        "        # Train model\n",
        "        return _train_catboost_model(\n",
        "            _BEST_PARAMS, full_df, val_df, n_rounds, model_path\n",
        "        )\n",
        "\n",
        "    # Start with standard\n",
        "    syn = train_model(\"feature_matrix\", VAL_IDS, TEST_IDS, \"syn_catboost_model.cbm\")\n",
        "    # Then complex\n",
        "    ran = train_model(\"feature_matrix_complex\", VAL_IDS, TEST_IDS, \"ran_catboost_model.cbm\")\n",
        "\n",
        "    return syn, ran\n",
        "\n",
        "\n",
        "syn, ran = train_syn_and_ran_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok Models are trained. Synthetic case performed significantly better in validation with ~93% Accuracy@1 whereas the placebo set achieved ~45% Accuracy@1.\n",
        "\n",
        "Let's run the test set to be sure."
      ],
      "metadata": {
        "id": "RWr9Gxaxn_Xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_on_test(model, test_ids_path, data_table: str, label=\"\"):\n",
        "    # Load test IDs\n",
        "    test_ids = pd.read_csv(test_ids_path)[\"test_ids\"].dropna().astype(int).tolist()\n",
        "    test_ids_set = set(test_ids)\n",
        "\n",
        "    # Load test rows from DB\n",
        "    with sqlite3.connect(_DB_PATH) as conn:\n",
        "        test_df = pd.read_sql_query(\n",
        "            f\"SELECT * FROM {data_table} WHERE clean_row_id IN ({','.join(map(str, test_ids_set))})\",\n",
        "            conn,\n",
        "        )\n",
        "\n",
        "    # Drop non-feature columns\n",
        "    drop_cols = [\"label\", \"clean_row_id\", \"investor\", \"firm\", \"template_id\"]\n",
        "    group_sizes = test_df.groupby(\"clean_row_id\", sort=False).size().tolist()\n",
        "    group_id = np.repeat(np.arange(len(group_sizes)), group_sizes)\n",
        "\n",
        "    X_test = test_df.drop(columns=drop_cols)\n",
        "    y_test = test_df[\"label\"]\n",
        "\n",
        "    test_pool = Pool(data=X_test, label=y_test, group_id=group_id)\n",
        "    test_df[\"score\"] = model.predict(test_pool)\n",
        "\n",
        "    acc1, recall3, mrr = _compute_ranking_metrics(test_df, k=3)\n",
        "    print(f\"\\nEvaluation Metrics ({label} Test Set):\")\n",
        "    print(f\"Accuracy@1 : {acc1:.4f}\")\n",
        "    print(f\"Recall@3   : {recall3:.4f}\")\n",
        "    print(f\"MRR        : {mrr:.4f}\")\n",
        "\n",
        "    return acc1, recall3, mrr\n",
        "\n",
        "# Evaluate both models on their test sets\n",
        "evaluate_on_test(syn, TEST_IDS, \"feature_matrix\", label=\"Synthetic\")\n",
        "evaluate_on_test(ran, TEST_IDS, \"feature_matrix_complex\", label=\"Random\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE38tdrvoBD-",
        "outputId": "cece3496-7ccb-4cfe-bc37-4e2d245cfc6e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1406598767.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  topk = df.groupby(\"clean_row_id\", group_keys=False).apply(\n",
            "/tmp/ipython-input-1406598767.py:58: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  mrr = df.groupby(\"clean_row_id\", group_keys=False).apply(reciprocal_rank).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics (Synthetic Test Set):\n",
            "Accuracy@1 : 0.9277\n",
            "Recall@3   : 0.9952\n",
            "MRR        : 0.9617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1406598767.py:45: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  topk = df.groupby(\"clean_row_id\", group_keys=False).apply(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics (Random Test Set):\n",
            "Accuracy@1 : 0.5091\n",
            "Recall@3   : 0.8916\n",
            "MRR        : 0.6983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1406598767.py:58: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  mrr = df.groupby(\"clean_row_id\", group_keys=False).apply(reciprocal_rank).mean()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.5091141669331628),\n",
              " np.float64(0.8915893827950112),\n",
              " np.float64(0.698321803162877))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}